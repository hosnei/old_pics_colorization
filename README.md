# ğŸ¨ Old Pictures Colorization â€” Deep Learning with U-Net

This project implements a *deep learning pipeline* to colorize grayscale images using a *U-Net model* trained on the *Downsampled ImageNet-64 dataset*.  
It converts the dataset into folders of PNGs, trains a U-Net for RGB color prediction, evaluates performance using *L1* and *SSIM, and supports **fine-tuning* and *visualization* on custom real-world images.

---

## ğŸ“ Project Structure

```bash
old_pics_colorization/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ imagenet64/              # Raw ImageNet-64 pickle/npz batches
â”‚   â”œâ”€â”€ converted64/             # Converted PNG dataset (train/val/test)
â”‚   â””â”€â”€ online_test_images/      # Custom real-world images for inference
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ images64_split.py        # Convert ImageNet64 pickle batches â†’ PNG folders
â”‚   â”œâ”€â”€ train64.py               # Train U-Net model from scratch
â”‚   â”œâ”€â”€ resume_train64.py        # Fine-tune existing model (mixed L1 + SSIM)
â”‚   â”œâ”€â”€ Unet64_preds.py          # Visualize predictions on test or custom images
â”‚   â”œâ”€â”€ evall.py                 # Evaluate trained models (L1 + SSIM metrics)
â”‚   â””â”€â”€ overtune_curves.py       # Plot learning curves & detect overfitting
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ checkpoints/             # Saved models 
â”‚   â”œâ”€â”€ plots/                   # Optional metrics/curve visualizations
â”‚   â”œâ”€â”€ predictions/             # Example outputs (gray vs predicted vs color) 
â”‚   â””â”€â”€ chosen classes/          # Saves labels of chosen classes when working with subsets 
â”‚  
â”‚
â””â”€â”€ README.md


```
# âš™ï¸ Installation
```
git clone https://github.com/hosnei/old_pics_colorization.git

cd old_pics_colorization
```
## (optional) create environment
```
python3 -m venv colorenv

source colorenv/bin/activate
```

## install dependencies
```
pip install -r requirements.txt
```

---

## ğŸ§  Model Overview

The model is a U-Net with skip connections between encoder and decoder stages:

Encoder: three downsampling blocks (Conv â†’ ReLU â†’ Pool)

Bottleneck: deepest feature extraction layer (512 channels)

Decoder: upsampling via transposed convolutions + concatenation with encoder features

Output: 3-channel RGB prediction (via tanh, scaled to [â€“1, 1])

Input format: (1, 64, 64) grayscale

Output format: (3, 64, 64) RGB colorized image


# ğŸ‹ï¸â€â™‚ï¸ Training

Convert the dataset (one-time operation):
```
python3 scripts/images64_split.py
```

Train the base model:
```
python3 scripts/train64.py
```

You can specify:

- number of epochs (epochs=10)

- learning rate (lr=1e-4)

- number of classes to train on (num_classes=100)

Example:
```
train_model(epochs=5, lr=1e-4, num_classes=100)
```

Fine-tune an existing model:
```
python3 scripts/resume_train64.py
```

# ğŸ“Š Evaluation

Evaluate L1 and SSIM metrics for any saved checkpoint:
```
python3 scripts/evall.py
```

Example output:

Model:  Models/unet_colorizer_1K.pt

Validation L1: 0.0920

Validation SSIM: 0.7900


You can also plot training vs validation curves with scripts/overtune_curves.py
to check for overfitting (high training accuracy but lower validation performance).

# ğŸ¨ Inference (Colorization)

Use the pretrained model to colorize new images:
```
python3 scripts/Unet64_preds.py
```

Then choose:

1ï¸âƒ£  Test set (by class ID)

2ï¸âƒ£  Custom folder (real-world images â†’ auto-grayscaled)


All colorized results will be displayed in a 3-row grid:

| Grayscale Input | Model Prediction | Original Color |

# ğŸ§© Fine-Tuning Details

- Loss: 0.5 * L1 + 0.5 * (1 - SSIM)

- Optimizer: AdamW (lr=1e-4, weight_decay=5e-5)

- Scheduler: CosineAnnealingLR

# Optional improvements:

- Replace BatchNorm with InstanceNorm2d

- Add light dropout (p=0.05â€“0.1) in decoder blocks

- Post-process outputs in HSV space to boost saturation & contrast

# ğŸ–¼ï¸ Example Results
Here are some sample outputs from the U-Net colorization model:

<p align="center">
  <img src="results/predictions/Figure_hayena_unet_1K.png" alt="Example colorization results" width="700"/>
</p>
	
	
# ğŸ§° Notes

Default image size: 64Ã—64

You can train on subsets (e.g., 10 or 100 ImageNet classes)

Models are saved in /results/checkpoints and automatically reloaded for fine-tuning

Supports GPU (cuda) or CPU fallback

# ğŸ§‘â€ğŸ’» Author

Housni TIBA
TÃ©lÃ©com Physique Strasbourg â€” Master ID

Deep Learning & Vision Projects | U-Net, CNN, Colorization, Optical AI

ğŸ“§ LinkedIn Profile : Housni Tiba

ğŸ“¦ GitHub: hosnei
